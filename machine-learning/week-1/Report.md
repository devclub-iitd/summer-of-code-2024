The first step was selecting a good database relevant to our tasks. Initially i chose IEEE classification dataset which was too bulky and contained many null values which were too difficult to clean on google collab with its limited ram. So I then shifted to Credit card fraud detection dataset which did not have null values and PCA was applied to it originally so feature engineering was not to be performed. I applied standardization as a part of data handling. The dataset was highly imbalanced with positive outcomes 0.174% of negative ones so I applied resampling techniques to balance the dataset and settled with borderline_smote for this. Next I applied neural network with the standard architecture of 12,8,1 nodes on three layers. I achieved an f1 score of 77% and an AUCPR score of 99.98%. This was much better than logistic regression with 13% f1 score and XGBoost with 65% f1 score. I tried SVM however it did not give any output for 20 minutes after which I decided to cancel its implementation for such a large dataset. 